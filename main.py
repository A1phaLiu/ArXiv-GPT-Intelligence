import time
import importlib
import sys
import os

# å¯¼å…¥ä¸šåŠ¡æ¨¡å—
from arxiv_client import fetch_latest_papers
from ai_service import summarize_paper
from db_manager import is_paper_processed, record_paper
from exporter import save_to_markdown

def is_interested(title, summary, keywords):
    """å…³é”®è¯åŒ¹é…è¿‡æ»¤"""
    content = (title + summary).lower()
    for kw in keywords:
        if kw.lower() in content:
            return True
    return False

def main():
    """
    æ‰§è¡Œè‡ªåŠ¨åŒ–æµæ°´çº¿ã€‚
    è¯¥å‡½æ•°ä¼šè¢« app.py è°ƒç”¨ã€‚
    """
    print("\n" + "="*50)
    print("ğŸš€ --- arXiv è®ºæ–‡è‡ªåŠ¨åŒ–æƒ…æŠ¥ç³»ç»Ÿä»»åŠ¡å¯åŠ¨ ---")
    
    # --- ã€æ ¸å¿ƒä¿®å¤é€»è¾‘ã€‘ç¡®ä¿é…ç½®å®æ—¶é‡è½½ ---
    # 1. æ£€æŸ¥ config æ˜¯å¦åœ¨ sys.modules ä¸­ï¼Œä¸åœ¨åˆ™å…ˆå¯¼å…¥
    if 'config' not in sys.modules:
        try:
            import config
        except ImportError:
            # å¦‚æœè·¯å¾„æœ‰é—®é¢˜ï¼Œå¼ºåˆ¶å°†å½“å‰ç›®å½•åŠ å…¥è·¯å¾„
            sys.path.append(os.path.dirname(os.path.abspath(__file__)))
            import config
    else:
        # 2. å¦‚æœå·²ç»åœ¨å†…å­˜ä¸­ï¼Œå¼ºåˆ¶é‡æ–°ä»ç£ç›˜åŠ è½½ï¼ˆä»¥è·å– app.py ä¿®æ”¹åçš„æ–°å‚æ•°ï¼‰
        import config
        importlib.reload(config)
    
    # æ‰“å°å½“å‰ç”Ÿæ•ˆçš„å‚æ•°ï¼Œç”¨äºè°ƒè¯•
    print(f"ğŸ“Š å½“å‰è¿è¡Œå‚æ•°: ")
    print(f"   - ç›‘æ§åˆ†ç±»: {config.HOT_CATEGORIES}")
    print(f"   - å…³é”®è¯: {config.FOCUS_KEYWORDS}")
    print(f"   - æŠ“å–ä¸Šé™: {config.MAX_RESULTS_PER_CATEGORY}")
    print("="*50 + "\n")

    # 1. è·å–æœ€æ–°è®ºæ–‡ (ä»æœ€æ–°çš„ config ä¸­è¯»å–)
    raw_papers = fetch_latest_papers()
    
    if not raw_papers:
        print("ğŸ“­ æœªèƒ½è·å–åˆ°è®ºæ–‡æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– arXiv çŠ¶æ€ã€‚")
        return

    new_summarized_papers = []
    processed_count = 0

    print(f"ğŸ§ æ­£åœ¨æ‰«æ {len(raw_papers)} ç¯‡è®ºæ–‡...")

    for paper in raw_papers:
        paper_id = paper.get_short_id()
        title = paper.title
        
        # 2. æŸ¥é‡
        if is_paper_processed(paper_id):
            continue

        # 3. è¿‡æ»¤ (ä½¿ç”¨åˆšåˆšé‡è½½åçš„å…³é”®è¯)
        if is_interested(title, paper.summary, config.FOCUS_KEYWORDS):
            print(f"ğŸ”¥ å‘½ä¸­å…³é”®è¯! æ­£åœ¨åˆ†æ: {title}")
            
            # 4. AI æ€»ç»“
            try:
                summary_cn = summarize_paper(title, paper.summary)
                pdf_url = paper.pdf_url
                
                # 5. å†™å…¥æ•°æ®åº“
                record_paper(
                    paper_id=paper_id, 
                    title=title, 
                    summary=summary_cn, 
                    url=pdf_url
                )
                
                new_summarized_papers.append({
                    "title": title,
                    "url": pdf_url,
                    "date": paper.published.date(),
                    "summary": summary_cn
                })
                
                processed_count += 1
                time.sleep(1) # ä¿æŠ¤ API
            except Exception as e:
                print(f"âŒ å¤„ç†è®ºæ–‡ {title} æ—¶å‡ºé”™: {e}")
        else:
            # ä¸æ„Ÿå…´è¶£ä¹Ÿè®°å½•ï¼Œé¿å…ä¸‹æ¬¡é‡å¤æ‰«æ
            record_paper(paper_id, title, "æœªå‘½ä¸­å…³é”®è¯ï¼Œè·³è¿‡æ€»ç»“", paper.pdf_url)

    # 6. ä»»åŠ¡æ”¶å°¾
    print("\n" + "="*30)
    print(f"âœ… ä»»åŠ¡å®Œæˆç»Ÿè®¡ï¼š")
    print(f"- æˆåŠŸåˆ†æå¹¶å½•å…¥: {processed_count} ç¯‡")
    
    if new_summarized_papers:
        report_path = save_to_markdown(new_summarized_papers)
        print(f"ğŸ“Š æœ¬æ¬¡æ–°å¢è®ºæ–‡æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    else:
        print("â˜• æœ¬æ¬¡æœªå‘ç°ç¬¦åˆå…³é”®è¯çš„æ–°è®ºæ–‡ã€‚")
    print("="*30)

if __name__ == "__main__":
    main()