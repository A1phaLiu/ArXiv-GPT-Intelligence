import streamlit as st
import sqlite3
import pandas as pd
import os
import time
from datetime import datetime

# å¯¼å…¥ä¸šåŠ¡æ¨¡å—
from main import main as start_main_task
import config # å¯¼å…¥ç°æœ‰é…ç½®

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI å­¦æœ¯çŒæ‰‹æ§åˆ¶å°",
    page_icon="ğŸ¹",
    layout="wide"
)

# è·¯å¾„é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ABS_DB_PATH = os.path.join(BASE_DIR, "arxiv_history.db")

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def save_config_permanently(categories, keywords, limit):
    """å°†ç½‘é¡µä¿®æ”¹çš„å‚æ•°æ°¸ä¹…å›å†™åˆ° config.py æ–‡ä»¶"""
    config_path = os.path.join(BASE_DIR, "config.py")
    content = f"""# config.py - è‡ªåŠ¨ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ (æ›´æ–°äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})

# ç›‘æ§çš„ arXiv åˆ†ç±»
HOT_CATEGORIES = {categories}

# æ€»ç»“è¿‡æ»¤å…³é”®è¯
FOCUS_KEYWORDS = {keywords}

# æ¯ä¸ªåˆ†ç±»ä¸‹æœ€å¤§æŠ“å–æ•°
MAX_RESULTS_PER_CATEGORY = {limit}

# å­˜å‚¨é…ç½®
DB_NAME = "arxiv_history.db"
REPORT_DIR = "reports"
"""
    with open(config_path, "w", encoding="utf-8") as f:
        f.write(content)

def load_local_data():
    """è¯»å–æ•°æ®åº“æ•°æ®"""
    if not os.path.exists(ABS_DB_PATH):
        return pd.DataFrame()
    try:
        conn = sqlite3.connect(ABS_DB_PATH)
        df = pd.read_sql("SELECT * FROM papers ORDER BY processed_at DESC", conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"æ•°æ®åº“è¯»å–å¤±è´¥: {e}")
        return pd.DataFrame()

# --- 3. ä¾§è¾¹æ ï¼šå‚æ•°é…ç½®ä¸äº¤äº’ ---
with st.sidebar:
    st.title("ğŸ› ï¸ ç³»ç»Ÿé…ç½®")
    st.info("åœ¨æ­¤ä¿®æ”¹å‚æ•°å°†æ°¸ä¹…åŒæ­¥è‡³ config.py")

    # é…ç½®é¡¹ 1ï¼šé¢†åŸŸé€‰æ‹©
    all_categories = ["cs.CL", "cs.AI", "cs.LG", "cs.CV", "cs.IR", "cs.RO", "stat.ML"]
    new_cats = st.multiselect(
        "é€‰æ‹©ç›‘æ§é¢†åŸŸ", 
        options=all_categories, 
        default=config.HOT_CATEGORIES
    )

    # é…ç½®é¡¹ 2ï¼šå…³é”®è¯è®¾ç½®
    current_kw_str = ", ".join(config.FOCUS_KEYWORDS)
    new_kw_input = st.text_area("ç›‘æ§å…³é”®è¯ (è‹±æ–‡é€—å·åˆ†éš”)", value=current_kw_str)
    new_keywords = [k.strip() for k in new_kw_input.split(",") if k.strip()]

    # é…ç½®é¡¹ 3ï¼šæŠ“å–æ•°é‡
    new_limit = st.slider("æŠ“å–æ•°é‡ä¸Šé™", 5, 100, config.MAX_RESULTS_PER_CATEGORY)

    st.divider()

    # åŠ¨ä½œæŒ‰é’®
    if st.button("ğŸš€ ä¿å­˜é…ç½®å¹¶å¯åŠ¨æŠ“å–", use_container_width=True, type="primary"):
        # 1. æ‰§è¡Œæ°¸ä¹…ä¿å­˜
        save_config_permanently(new_cats, new_keywords, new_limit)
        
        # 2. å¯åŠ¨ main.py é€»è¾‘
        with st.status("æ­£åœ¨åŒæ­¥æ•°æ®...", expanded=True) as status:
            try:
                # é‡æ–°åŠ è½½æ¨¡å—æˆ–ç›´æ¥ä¼ å…¥å‚æ•°è¿è¡Œ
                # è¿™é‡Œæˆ‘ä»¬ç›´æ¥è¿è¡Œ main()ï¼Œå®ƒä¼šè‡ªåŠ¨è¯»å–åˆšåˆšä¿å­˜çš„ config.py
                start_main_task()
                status.update(label="âœ… æ›´æ–°å®Œæˆ!", state="complete", expanded=False)
                st.toast("é…ç½®å·²ä¿å­˜ï¼Œæ•°æ®å·²æ›´æ–°ï¼")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"è¿è¡Œå¤±è´¥: {e}")
                status.update(label="âŒ å‡ºé”™", state="error")

    st.divider()
    search_term = st.text_input("ğŸ” æœç´¢åº“ä¸­è®ºæ–‡", "")

# --- 4. ä¸»ç•Œé¢ï¼šå†…å®¹å±•ç¤º ---
st.title("ğŸ“š AI è®ºæ–‡æ™ºèƒ½çœ‹æ¿")

df = load_local_data()

if df.empty:
    st.warning("ğŸ“­ æ•°æ®åº“ä¸ºç©ºã€‚è¯·åœ¨å·¦ä¾§é…ç½®å¥½å‚æ•°åç‚¹å‡»â€œå¯åŠ¨æŠ“å–â€ã€‚")
else:
    # æœç´¢è¿‡æ»¤
    if search_term:
        df = df[df['title'].str.contains(search_term, case=False) | 
                df['summary'].str.contains(search_term, case=False)]

    # ç»Ÿè®¡æŒ‡æ ‡
    c1, c2, c3 = st.columns(3)
    c1.metric("è®ºæ–‡æ€»æ•°", len(df))
    c2.metric("å½“å‰é¢†åŸŸæ•°", len(config.HOT_CATEGORIES))
    c3.metric("æœ€åæ›´æ–°æ—¶é—´", df['processed_at'].iloc[0][:16])

    st.divider()

    # è®ºæ–‡åˆ—è¡¨æ¸²æŸ“
    for idx, row in df.iterrows():
        with st.expander(f"ğŸ“… {row['processed_at'][:10]} | {row['title']}", expanded=(idx == 0)):
            col_main, col_side = st.columns([3, 1])
            
            with col_main:
                st.markdown("##### ğŸ¤– AI æ·±åº¦æ€»ç»“")
                st.markdown(row['summary'])
            
            with col_side:
                st.markdown("##### ğŸ“„ ä¿¡æ¯")
                st.write(f"ID: `{row['paper_id']}`")
                st.link_button("ğŸ”— æŸ¥çœ‹åŸæ–‡", row['url'], use_container_width=True)
            
            st.divider()

# --- é¡µè„š ---
st.caption("Powered by Gemini & Streamlit | æ‚¨çš„ä¸“å±å­¦æœ¯æƒ…æŠ¥å‘˜")